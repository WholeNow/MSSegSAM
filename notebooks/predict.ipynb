{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# finestSAM - Automatic Predictions\n",
                "\n",
                "<a target=\"_blank\" href=\"https://colab.research.google.com/github/WholeNow/MSSegSAM/blob/main/notebooks/predict.ipynb\">\n",
                "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
                "</a>\n",
                "\n",
                "This notebook generates segmentation predictions using **SAM automatic mask generation** on new images using a trained model checkpoint."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Setting Up the Environment\n",
                "This notebook is designed to be run in both Google Colab and local Jupyter Notebook environments. \n",
                "The following cell detects the environment and sets up the necessary paths accordingly."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "\n",
                "# Environment detection\n",
                "try:\n",
                "    import google.colab\n",
                "    IS_COLAB = True\n",
                "except ImportError:\n",
                "    IS_COLAB = False\n",
                "\n",
                "if IS_COLAB:\n",
                "    BASE_PATH = \"/content\"\n",
                "\n",
                "    # Clone repository\n",
                "    repo_name = \"MSSegSAM\"\n",
                "    repo_url = \"https://github.com/WholeNow/MSSegSAM.git\"\n",
                "    repo_path = os.path.join(BASE_PATH, repo_name)\n",
                "\n",
                "    if not os.path.exists(repo_path):\n",
                "        !git clone {repo_url}\n",
                "\n",
                "    BASE_PATH = os.path.join(BASE_PATH, repo_name)\n",
                "\n",
                "    # Install dependencies\n",
                "    requirements_path = os.path.join(BASE_PATH, \"requirements.txt\")\n",
                "    !pip install -r {requirements_path}\n",
                "else:\n",
                "    # If local, assume the execution directory is 'notebooks' and move one level up\n",
                "    BASE_PATH = os.getcwd()\n",
                "    BASE_PATH = os.path.abspath(os.path.join(BASE_PATH, os.pardir)) \n",
                "\n",
                "print(f\"Environment initialized at: {BASE_PATH}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Configuration\n",
                "Specify the input image path and the model checkpoint to use.\n",
                "\n",
                " * `INPUT_IMAGE_PATH`: Path to the .png or .jpg image.\n",
                " * `CHECKPOINT_FILE`: The name of the .pth file saved during training (by default located in `finestSAM/sav`).\n",
                " * `CHECKPOINT_TYPE`: The type of the `CHECKPOINT_FILE` (`vit_b`, `vit_l`, `vit_h`).\n",
                " * `OPACITY`: Visual opacity of the predicted mask overlay (0.0 - 1.0)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "INPUT_IMAGE_PATH = \"path/to/your/image.png\"\n",
                "OPACITY = 0.9\n",
                "\n",
                "# Optional: Specify a trained checkpoint \n",
                "# (if you not specify it, the default checkpoint in the config file will be used)\n",
                "CHECKPOINT_FILE = \"best.pt\"\n",
                "CHECKPOINT_PATH = os.path.join(BASE_PATH, \"finestSAM\", \"sav\", CHECKPOINT_FILE)\n",
                "MODEL_TYPE = \"vit_b\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Run Prediction\n",
                "The following command executes the prediction and saves the result to the output directory (defined in [`finestSAM/config.py`](../finestSAM/config.py), default: `out/`)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Switch to model directory\n",
                "os.chdir(BASE_PATH)\n",
                "\n",
                "cmd_args = f\"--mode predict --input \\\"{INPUT_IMAGE_PATH}\\\" --opacity {OPACITY}\"\n",
                "\n",
                "if os.path.exists(CHECKPOINT_PATH):\n",
                "    cmd_args += f\" --checkpoint \\\"{CHECKPOINT_PATH}\\\" --model_type {MODEL_TYPE}\"\n",
                "else:\n",
                "    print(f\"Warning: Checkpoint {CHECKPOINT_PATH} not found. Using default config checkpoint.\")\n",
                "\n",
                "if os.path.exists(INPUT_IMAGE_PATH):\n",
                "    !python finestSAM {cmd_args}\n",
                "else:\n",
                "    print(f\"Error: Input image not found at {INPUT_IMAGE_PATH}\")\n",
                "\n",
                "# Return to base directory\n",
                "os.chdir(BASE_PATH)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "ML",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
