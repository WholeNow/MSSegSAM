{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# finestSAM - Train\n",
                "\n",
                "<a target=\"_blank\" href=\"https://colab.research.google.com/github/WholeNow/MSSegSAM/blob/main/notebooks/train.ipynb\">\n",
                "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
                "</a>\n",
                "\n",
                "### Checkpoint Information\n",
                "The checkpoint downloaded by default is the original **Meta SAM (ViT-B)** model.\n",
                "\n",
                "> **To use a different checkpoint:**\n",
                "> 1. Consult the [README](../finestSAM/sav/README.md) in the `finestSAM/sav` directory for download links.\n",
                "> 2. Update the `finestSAM/config.py` file:\n",
                ">    - Set `cfg.model.type` to the correct type (e.g., 'vit_h', 'vit_l', 'vit_b').\n",
                ">    - Set `cfg.model.checkpoint` to the filename of your new checkpoint."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "# Environment detection\n",
                "try:\n",
                "    import google.colab\n",
                "    IS_COLAB = True\n",
                "except ImportError:\n",
                "    IS_COLAB = False\n",
                "\n",
                "if IS_COLAB:\n",
                "    BASE_PATH = \"/content\"\n",
                "    \n",
                "    # Install dependencies\n",
                "    %pip install -q Lightning segmentation_models_pytorch wget\n",
                "\n",
                "    # Clone repository\n",
                "    repo_name = \"MSSegSAM\"\n",
                "    repo_url = \"https://github.com/WholeNow/MSSegSAM.git\"\n",
                "    repo_path = os.path.join(BASE_PATH, repo_name)\n",
                "\n",
                "    if not os.path.exists(repo_path):\n",
                "        !git clone {repo_url}\n",
                "\n",
                "    BASE_PATH = os.path.join(BASE_PATH, repo_name)\n",
                "else:\n",
                "    BASE_PATH = os.getcwd()\n",
                "\n",
                "import wget\n",
                "\n",
                "# Checkpoint verification\n",
                "CHECKPOINT_DIR = os.path.join(BASE_PATH, \"finestSAM\", \"sav\")\n",
                "CHECKPOINT_URL = \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\"\n",
                "CHECKPOINT_PATH = os.path.join(CHECKPOINT_DIR, \"sam_vit_b_01ec64.pth\")\n",
                "\n",
                "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
                "\n",
                "if not os.path.exists(CHECKPOINT_PATH):\n",
                "    wget.download(CHECKPOINT_URL, out=CHECKPOINT_DIR)\n",
                "\n",
                "print(f\"Environment initialized in: {BASE_PATH}\")\n",
                "\n",
                "# Path definitions\n",
                "DATA_PREP_DIR = os.path.join(BASE_PATH, \"prep_data\")\n",
                "RAW_DATA_DIR = os.path.join(DATA_PREP_DIR, \"Datasets_raw\")\n",
                "COCO_DIR = os.path.join(DATA_PREP_DIR, \"Datasets_COCO\")\n",
                "\n",
                "print(f\"Data Prep Directory: {DATA_PREP_DIR}\")\n",
                "print(f\"Raw Data Directory:  {RAW_DATA_DIR}\")\n",
                "print(f\"Output Directory:    {COCO_DIR}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# # Configuration for Dataset Creation\n",
                "# SCRIPT_PATH = os.path.join(DATA_PREP_DIR, \"create_dataset.py\")\n",
                "\n",
                "# INPUT_PATH = os.path.join(RAW_DATA_DIR, \"DatasetProcessed\")\n",
                "# DATASET_PATH = os.path.join(COCO_DIR, \"dataset\") \n",
                "\n",
                "# DATASET_IDS = \"all\"\n",
                "# MODALITY = \"T1\"\n",
                "# SLICE_RANGE = \"all\"\n",
                "# REMOVE_EMPTY_SLICES = True\n",
                "\n",
                "# # Define dataset path for training\n",
                "# TRAIN_DATASET_PATH = DATASET_PATH\n",
                "\n",
                "# if os.path.exists(TRAIN_DATASET_PATH):\n",
                "#     print(f\"Dataset already exists at {TRAIN_DATASET_PATH}, creation can be skipped if not needed.\")\n",
                "# else:\n",
                "#     if os.path.exists(SCRIPT_PATH):\n",
                "#         flag_empty = \"--remove_empty\" if REMOVE_EMPTY_SLICES else \"\"\n",
                "\n",
                "#         !python \"{SCRIPT_PATH}\" \\\n",
                "#             --input_dir \"{INPUT_PATH}\" \\\n",
                "#             --output_dir \"{TRAIN_DATASET_PATH}\" \\\n",
                "#             --dataset_ids {DATASET_IDS} \\\n",
                "#             --modality {MODALITY} \\\n",
                "#             --slice_range {SLICE_RANGE} \\\n",
                "#             {flag_empty}\n",
                "#     else:\n",
                "#         print(f\"Error: create_dataset.py not found in {DATA_PREP_DIR}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "DATASET_PATH = os.path.join(COCO_DIR, \"dataset\") "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Switch to model directory\n",
                "os.chdir(BASE_PATH)\n",
                "\n",
                "print(f\"Starting training...\")\n",
                "print(f\"Target Dataset: {DATASET_PATH}\")\n",
                "\n",
                "# Run Train\n",
                "%run finestSAM/__main__.py --mode train --dataset \"{DATASET_PATH}\"\n",
                "\n",
                "# Return to base directory\n",
                "os.chdir(BASE_PATH)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "ML",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
