{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# MSSegSAM Data Preparation Pipeline\n",
                "\n",
                "This notebook streamlines the data preparation process for training the MSSegSAM model.\n",
                "\n",
                "The pipeline is organized into two sequential phases:\n",
                "\n",
                "1.  **Phase 1: Preprocessing and Standardization (MRI $\\rightarrow$ NIfTI MNI152)**\n",
                "    *   Transforming heterogeneous raw data into a standardized format.\n",
                "    *   Applying s<kull stripping, MNI space registration, and bias field correction.\n",
                "\n",
                "2.  **Phase 2: COCO Format Conversion (NIfTI $\\rightarrow$ COCO JSON)**\n",
                "    *   Extracting 2D slices from 3D volumes.\n",
                "    *   Generating training annotations in the standard MS-COCO format.\n",
                "\n",
                "> [!NOTE]\n",
                "> The code is designed to be run on CPUs."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Setting Up the Environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "16d67ccb",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "from pathlib import Path\n",
                "import multiprocessing\n",
                "\n",
                "current_dir = Path(os.getcwd())\n",
                "project_root = current_dir.parent\n",
                "if str(project_root) not in sys.path:\n",
                "    sys.path.append(str(project_root))\n",
                "\n",
                "try:\n",
                "    import src.pipeline as pipeline_module\n",
                "    import src.coco_converter as coco_module\n",
                "    print(\"Modules loaded successfully.\")\n",
                "except ImportError as e:\n",
                "    print(f\"Error importing modules: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "123d4423",
            "metadata": {},
            "source": [
                "## Phase 1: Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "921e67fb",
            "metadata": {},
            "outputs": [],
            "source": [
                "cpu_count = multiprocessing.cpu_count()\n",
                "MAX_WORKERS = max(1, cpu_count - 1)\n",
                "print(f\"Resources detected: {cpu_count} CPU.\")\n",
                "print(f\"Maximum number of workers: {MAX_WORKERS}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ad2572cb",
            "metadata": {},
            "outputs": [],
            "source": [
                "INPUT_RAW_DIR = \"../Datasets_Raw\"\n",
                "OUTPUT_PROC_DIR = \"../Datasets_Process\"\n",
                "\n",
                "# Config\n",
                "VERBOSE = False\n",
                "WORKERS = MAX_WORKERS "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "48844a42",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run preprocessing\n",
                "try:\n",
                "    pipeline_module.run(INPUT_RAW_DIR, OUTPUT_PROC_DIR, workers=WORKERS, verbose=VERBOSE)\n",
                "except Exception as e:\n",
                "    print(f\"\\nError during preprocessing: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dda1ed60",
            "metadata": {},
            "source": [
                "### Train/Val/Test Split\n",
                "\n",
                "After Phase 1, the data is organized in the structure: Dataset -> Patient -> Timepoint.\n",
                "\n",
                "Before COCO conversion, it is recommended to organize the data into `train`, `val` and `test` subfolders within each dataset.\n",
                "\n",
                "The COCO converter automatically detects these folders. If the data is already divided, the converter will generate three separate JSON files (`train/annotations.json`, `val/...`, `test/...`), ready for model training. If the data is not divided, a single \"flat\" dataset will be generated.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "83109a13",
            "metadata": {},
            "source": [
                "# Phase 2: Conversion to COCO Format\n",
                "\n",
                "| Parameter | Type | Description | Default |\n",
                "| :--- | :--- | :--- | :--- |\n",
                "| **`input_dir`** | `str` | Root directory containing **Processed** datasets. | **Required** |\n",
                "| **`output_dir`** | `str` | Target directory for the generated COCO dataset. | `dataset_COCO` |\n",
                "| **`dataset_names`** | `list` | List of sub-datasets names to process. `[\"Dataset1\", \"Dataset2\"]` OR `[\"all\"]`. | `[\"all\"]` |\n",
                "| **`slice_range`** | `list` | Defines which axial slices to extract from the 3D volume. `[\"0\", \"181\"]` OR `[\"all\"]`. | `[\"all\"]` |\n",
                "| **`slice_step`** | `int` | Step for slicing volume (e.g., 5 = extract every 5th slice). | `1` |\n",
                "| **`remove_empty`** | `bool` | If True, skips slices with no Ground Truth lesions. | `False` |\n",
                "| **`all_timepoints`** | `bool` | If True, process all timepoints instead of just the last one. | `False` |\n",
                "| **`modality`** | `str` | MRI modality to extract (`T1`, `T2`, `FLAIR`). | `\"FLAIR\"` |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "224553f9",
            "metadata": {},
            "outputs": [],
            "source": [
                "INPUT_NIFTI_DIR = \"../Datasets_Processed\"\n",
                "OUTPUT_COCO_DIR = \"../../Dataset\"\n",
                "\n",
                "# Config\n",
                "DATASET_NAMES = [\"all\"]\n",
                "SLICE_RANGE = [\"all\"]\n",
                "SLICE_STEP = 4\n",
                "REMOVE_EMPTY = True\n",
                "ALL_TIMEPOINTS = False\n",
                "MODALITY = \"FLAIR\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "418554da",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run COCO conversion\n",
                "converter = coco_module.COCOConverter(\n",
                "    input_dir=INPUT_NIFTI_DIR,\n",
                "    output_dir=OUTPUT_COCO_DIR,\n",
                "    dataset_names=DATASET_NAMES,\n",
                "    slice_range=SLICE_RANGE,\n",
                "    slice_step=SLICE_STEP,\n",
                "    modality=MODALITY,\n",
                "    remove_empty=REMOVE_EMPTY,\n",
                "    all_timepoints=ALL_TIMEPOINTS\n",
                ")\n",
                "\n",
                "try:\n",
                "    converter.run()\n",
                "except Exception as e:\n",
                "    print(f\"\\nError during COCO conversion: {e}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "ML",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
